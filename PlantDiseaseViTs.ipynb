{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#setup kaggle API key as env variables\n",
        "import json\n",
        "import os\n",
        "kaggle_credentails = json.load(open('/content/kaggle.json'))\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentails['username']\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentails['key']"
      ],
      "metadata": {
        "id": "UD8vjEyyT-Du"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d abdallahalidev/plantvillage-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n10rm9yUCjX",
        "outputId": "89512dfb-942d-48f1-983c-e81541f7b6da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading plantvillage-dataset.zip to /content\n",
            " 99% 2.01G/2.04G [00:14<00:00, 251MB/s]\n",
            "100% 2.04G/2.04G [00:14<00:00, 153MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip the downloaded dataset\n",
        "import zipfile\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('plantvillage-dataset.zip', 'r') as z:\n",
        "   z.extractall()"
      ],
      "metadata": {
        "id": "XtI6gEPQUQaZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'plantvillage dataset/color'"
      ],
      "metadata": {
        "id": "UBTga-I0UVEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install patchify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su4xcgrOUnqA",
        "outputId": "552b2576-8450-4ee6-fa44-9cd7d83d1f0d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from patchify) (1.26.4)\n",
            "Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHqAw5vHUtcy",
        "outputId": "f11cc672-931b-4410-8425-98d45b3b237c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit\n",
            "  Downloading vit-2.3.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting tasklib>=2.4.3 (from vit)\n",
            "  Downloading tasklib-2.5.1.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urwid>=2.1.2 (from vit)\n",
            "  Downloading urwid-2.6.16-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from urwid>=2.1.2->vit) (4.12.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid>=2.1.2->vit) (0.2.13)\n",
            "Downloading vit-2.3.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urwid-2.6.16-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tasklib\n",
            "  Building wheel for tasklib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tasklib: filename=tasklib-2.5.1-py3-none-any.whl size=25472 sha256=2fd66ae359a66721d8f04265be87d62b3c28f5eb18f0241ab7fbae13670e3c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/97/8f/5067ac7e7a734bd4ffca090afa19a4498409f189cceb02cc1b\n",
            "Successfully built tasklib\n",
            "Installing collected packages: tasklib, urwid, vit\n",
            "Successfully installed tasklib-2.5.1 urwid-2.6.16 vit-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDP8P0ANU1hW",
        "outputId": "fb891d01-7479-433e-a1e2-c64971c5b1b9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow_addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vit.py\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class ClassToken(Layer):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        w_init = tf.random_normal_initializer()\n",
        "        self.w = tf.Variable(\n",
        "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
        "            trainable = True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        hidden_dim = self.w.shape[-1]\n",
        "\n",
        "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim]) # change the shape\n",
        "        cls = tf.cast(cls, dtype=inputs.dtype) # change the datatype\n",
        "        return cls\n",
        "\n",
        "def mlp(x, cf):\n",
        "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    x = Dense(cf[\"hidden_dim\"])(x)\n",
        "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
        "    return x\n",
        "\n",
        "def transformer_encoder(x, cf):\n",
        "    skip_1 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = MultiHeadAttention(num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"])(x, x)\n",
        "    x = Add()([x, skip_1])\n",
        "\n",
        "    skip_2 = x\n",
        "    x = LayerNormalization()(x)\n",
        "    x = mlp(x, cf)\n",
        "    x = Add()([x, skip_2])\n",
        "\n",
        "    return x\n",
        "\n",
        "def ViT(cf):\n",
        "\n",
        "    \"\"\" Inputs \"\"\"\n",
        "    input_shape = (cf[\"num_patches\"], cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
        "    print(\"input_shape\",input_shape)\n",
        "    inputs = Input(input_shape)     ## (None, 64, 1875)\n",
        "\n",
        "    \"\"\" Patch + Position Embeddings \"\"\"\n",
        "    patch_embed = Dense(cf[\"hidden_dim\"])(inputs)   ## (None, 64, 768)\n",
        "    print(\"patch_embed\",patch_embed.shape)\n",
        "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
        "    #print(\"positions\",positions)\n",
        "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (64, 768)\n",
        "    print(\"pos_embed\",pos_embed.shape)\n",
        "    embed = patch_embed + pos_embed ## (None, 64, 768)\n",
        "    print(\"embed\",embed.shape)\n",
        "\n",
        "\n",
        "    \"\"\" Adding Class Token \"\"\"\n",
        "    token = ClassToken()(embed)\n",
        "    print(\"token\",token.shape)\n",
        "    x = Concatenate(axis=1)([token, embed]) ## (None, 64, 768) # 65+1 token patch and 768 reduced dim\n",
        "    print(\"x\",x.shape)\n",
        "    for _ in range(cf[\"num_layers\"]):\n",
        "        x = transformer_encoder(x, cf)\n",
        "\n",
        "    \"\"\" Classification Head \"\"\"\n",
        "    x = LayerNormalization()(x)     ## (None, 65, 768)\n",
        "    x = x[:, 0, :]\n",
        "    x = Dense(cf[\"num_classes\"], activation=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, x)\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = {}\n",
        "    config[\"num_layers\"] = 6 #reduce num_layers from 12\n",
        "    config[\"hidden_dim\"] = 384 #reduce hidden_dim from 768\n",
        "    config[\"mlp_dim\"] = 1536 #reduce mlp_dim from 3072\n",
        "    config[\"num_heads\"] = 6 #reduce num_heads from 12\n",
        "    config[\"dropout_rate\"] = 0.1\n",
        "    config[\"num_patches\"] = 64\n",
        "    config[\"patch_size\"] = 25\n",
        "    config[\"num_channels\"] = 3\n",
        "    config[\"num_classes\"] = 38\n",
        "\n",
        "    model = ViT(config)\n",
        "    model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEhEJa58VIFv",
        "outputId": "e6167eee-3bff-452b-8eaf-8136162d1a38"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vit.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit_keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Q3EjbcU6po",
        "outputId": "c10c902a-092c-4184-f480-7a6fe31aa5d5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vit_keras\n",
            "  Downloading vit_keras-0.1.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vit_keras) (1.13.1)\n",
            "Collecting validators (from vit_keras)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->vit_keras) (1.26.4)\n",
            "Downloading vit_keras-0.1.2-py3-none-any.whl (24 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, vit_keras\n",
            "Successfully installed validators-0.34.0 vit_keras-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from patchify import patchify\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
        "from vit import ViT\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "hp = {}\n",
        "hp[\"image_size\"] = 200\n",
        "hp[\"num_channels\"] = 3\n",
        "hp[\"patch_size\"] = 25\n",
        "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
        "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
        "\n",
        "hp[\"batch_size\"] = 8\n",
        "hp[\"lr\"] = 1e-4\n",
        "hp[\"num_epochs\"] = 500\n",
        "hp[\"num_classes\"] = 38\n",
        "hp[\"class_names\"] = ['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust',  'Apple___healthy',  'Blueberry___healthy', 'Cherry_(including_sour)___Powdery_mildew',  'Cherry_(including_sour)___healthy', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',  'Corn_(maize)___Common_rust_',  'Corn_(maize)___Northern_Leaf_Blight',  'Corn_(maize)___healthy',  'Grape___Black_rot',  'Grape___Esca_(Black_Measles)',  'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',  'Grape___healthy',  'Orange___Haunglongbing_(Citrus_greening)',  'Peach___Bacterial_spot',  'Peach___healthy', 'Pepper,_bell___Bacterial_spot',  'Pepper,_bell___healthy',  'Potato___Early_blight',  'Potato___Late_blight',  'Potato___healthy',  'Raspberry___healthy',  'Soybean___healthy',  'Squash___Powdery_mildew',  'Strawberry___Leaf_scorch',  'Strawberry___healthy',  'Tomato___Bacterial_spot',  'Tomato___Early_blight',  'Tomato___Late_blight',  'Tomato___Leaf_Mold',  'Tomato___Septoria_leaf_spot',  'Tomato___Spider_mites Two-spotted_spider_mite',  'Tomato___Target_Spot',  'Tomato___Tomato_Yellow_Leaf_Curl_Virus',  'Tomato___Tomato_mosaic_virus',  'Tomato___healthy']\n",
        "\n",
        "\n",
        "hp[\"num_layers\"] = 12\n",
        "hp[\"hidden_dim\"] = 768\n",
        "hp[\"mlp_dim\"] = 3072\n",
        "hp[\"num_heads\"] = 12\n",
        "hp[\"dropout_rate\"] = 0.1\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path, split=0.1):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "\n",
        "    return train_x, valid_x, test_x\n",
        "\n",
        "def tf_dataset(images, batch=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "    return ds\n",
        "\n",
        "def process_image_label(path):\n",
        "    \"\"\" Reading images \"\"\"\n",
        "    path = path.decode() # Convert tensor to string\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
        "    image = image/255.0\n",
        "\n",
        "    \"\"\" Preprocessing to patches \"\"\"\n",
        "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
        "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
        "    print(\"patches\",patches.shape)\n",
        "\n",
        "    patches = np.reshape(patches, (64, 25, 25, 3))\n",
        "    for i in range(64):\n",
        "         cv2.imwrite(f\"files/{i}.png\", patches[i])\n",
        "\n",
        "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
        "    patches = patches.astype(np.float32)\n",
        "\n",
        "    \"\"\" Label \"\"\"\n",
        "    class_name = path.split(\"\\\\\")[-2]\n",
        "    #print('class_name',class_name)\n",
        "    class_idx = hp[\"class_names\"].index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return patches, class_idx\n",
        "\n",
        "def parse(path):\n",
        "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
        "\n",
        "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
        "    labels.set_shape(hp[\"num_classes\"])\n",
        "\n",
        "    return patches, labels\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory for storing files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Paths \"\"\"\n",
        "    dataset_path = r'plantvillage dataset/color'\n",
        "\n",
        "    model_path = os.path.join(\"files\", \"model.keras\")\n",
        "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    train_x, valid_x, test_x = load_data(dataset_path)\n",
        "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "    train_ds = tf_dataset(train_x, batch=hp[\"batch_size\"])\n",
        "    valid_ds = tf_dataset(valid_x, batch=hp[\"batch_size\"])\n",
        "\n",
        "    model = ViT(hp)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
        "        metrics=[\"acc\"]\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
        "    ]\n",
        "    \"\"\"\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        epochs=hp[\"num_epochs\"],\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLiM6k-Qhs-0",
        "outputId": "c4b5f228-0f6c-4ef7-db39-3981c4af9c78"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1200 - Valid: 150 - Test: 150\n",
            "input_shape (64, 1875)\n",
            "patch_embed (None, 64, 768)\n",
            "pos_embed (64, 768)\n",
            "embed (None, 64, 768)\n",
            "token (None, 1, 768)\n",
            "x (None, 65, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKrep2oZTzBh",
        "outputId": "6c41ba45-0e38-4300-bd62-8c5c334a8a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from patchify import patchify\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping\n",
        "from vit import ViT\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "hp = {}\n",
        "hp[\"image_size\"] = 100 # Reduce image_size from 200\n",
        "hp[\"num_channels\"] = 3\n",
        "hp[\"patch_size\"] = 10 # Reduce patch_size from 25\n",
        "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
        "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
        "\n",
        "hp[\"batch_size\"] = 4 # Reduce batch_size from 8\n",
        "hp[\"lr\"] = 1e-4\n",
        "hp[\"num_epochs\"] = 500\n",
        "hp[\"num_classes\"] = 38\n",
        "hp[\"class_names\"] = ['Apple___Apple_scab',  'Apple___Black_rot',  'Apple___Cedar_apple_rust',  'Apple___healthy', 'Blueberry___healthy',  'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',  'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',  'Corn_(maize)___Common_rust_',  'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy',  'Grape___Black_rot',  'Grape___Esca_(Black_Measles)',  'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',  'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)',  'Peach___Bacterial_spot',  'Peach___healthy',  'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy',  'Potato___Early_blight',  'Potato___Late_blight',  'Potato___healthy',  'Raspberry___healthy',  'Soybean___healthy',  'Squash___Powdery_mildew',  'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot',  'Tomato___Early_blight',  'Tomato___Late_blight',  'Tomato___Leaf_Mold',  'Tomato___Septoria_leaf_spot',  'Tomato___Spider_mites Two-spotted_spider_mite',  'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
        "\n",
        "\n",
        "\n",
        "hp[\"num_layers\"] = 6 #reduce num_layers from 12\n",
        "hp[\"hidden_dim\"] = 384 #reduce hidden_dim from 768\n",
        "hp[\"mlp_dim\"] = 1536 #reduce mlp_dim from 3072\n",
        "hp[\"num_heads\"] = 6 #reduce num_heads from 12\n",
        "hp[\"dropout_rate\"] = 0.1\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_data(path, split=0.1):\n",
        "    images = shuffle(glob(os.path.join(path, \"*\", \"*.jpg\")))\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "\n",
        "    return train_x, valid_x, test_x\n",
        "\n",
        "def tf_dataset(images, batch=32):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((images))\n",
        "    ds = ds.map(parse).batch(batch).prefetch(8)\n",
        "    return ds\n",
        "\n",
        "def process_image_label(path):\n",
        "    \"\"\" Reading images \"\"\"\n",
        "    path = path.decode() # Convert tensor to string\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (hp[\"image_size\"], hp[\"image_size\"]))\n",
        "    image = image/255.0\n",
        "\n",
        "    \"\"\" Preprocessing to patches \"\"\"\n",
        "    patch_shape = (hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"])\n",
        "    patches = patchify(image, patch_shape, hp[\"patch_size\"])\n",
        "    #print(\"patches\",patches.shape)\n",
        "\n",
        "    patches = np.reshape(patches, (hp[\"num_patches\"], hp[\"patch_size\"], hp[\"patch_size\"], hp[\"num_channels\"]))\n",
        "    #for i in range(hp[\"num_patches\"]):\n",
        "         #cv2.imwrite(f\"files/{i}.png\", patches[i])\n",
        "\n",
        "    patches = np.reshape(patches, hp[\"flat_patches_shape\"])\n",
        "    patches = patches.astype(np.float32)\n",
        "\n",
        "    \"\"\" Label \"\"\"\n",
        "    class_name = path.split(\"/\")[-2] #fixed path\n",
        "    #print('class_name',class_name)\n",
        "    class_idx = hp[\"class_names\"].index(class_name)\n",
        "    class_idx = np.array(class_idx, dtype=np.int32)\n",
        "\n",
        "    return patches, class_idx\n",
        "\n",
        "def parse(path):\n",
        "    patches, labels = tf.numpy_function(process_image_label, [path], [tf.float32, tf.int32])\n",
        "    labels = tf.one_hot(labels, hp[\"num_classes\"])\n",
        "\n",
        "    patches.set_shape(hp[\"flat_patches_shape\"])\n",
        "    labels.set_shape(hp[\"num_classes\"])\n",
        "\n",
        "    return patches, labels\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Directory for storing files \"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\" Paths \"\"\"\n",
        "    dataset_path = r'plantvillage dataset/color'\n",
        "\n",
        "    model_path = os.path.join(\"files\", \"model.keras\")\n",
        "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    train_x, valid_x, test_x = load_data(dataset_path)\n",
        "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "    train_ds = tf_dataset(train_x, batch=hp[\"batch_size\"])\n",
        "    valid_ds = tf_dataset(valid_x, batch=hp[\"batch_size\"])\n",
        "\n",
        "    model = ViT(hp)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"], clipvalue=1.0),\n",
        "        metrics=[\"acc\"]\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-10, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        epochs=hp[\"num_epochs\"],\n",
        "        validation_data=valid_ds,\n",
        "        callbacks=callbacks\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from patchify import patchify\n",
        "import tensorflow as tf\n",
        "from train import load_data, tf_dataset\n",
        "from vit import ViT\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "hp = {}\n",
        "hp[\"image_size\"] = 100 # Reduce image_size from 200\n",
        "hp[\"num_channels\"] = 3\n",
        "hp[\"patch_size\"] = 10 # Reduce patch_size from 25\n",
        "hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
        "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
        "\n",
        "hp[\"batch_size\"] = 4 # Reduce batch_size from 8\n",
        "hp[\"lr\"] = 1e-4\n",
        "hp[\"num_epochs\"] = 500\n",
        "hp[\"num_classes\"] = 38\n",
        "hp[\"class_names\"] = ['Apple___Apple_scab',  'Apple___Black_rot',  'Apple___Cedar_apple_rust',  'Apple___healthy', 'Blueberry___healthy',  'Cherry_(including_sour)___Powdery_mildew', 'Cherry_(including_sour)___healthy',  'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',  'Corn_(maize)___Common_rust_',  'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy',  'Grape___Black_rot',  'Grape___Esca_(Black_Measles)',  'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',  'Grape___healthy', 'Orange___Haunglongbing_(Citrus_greening)',  'Peach___Bacterial_spot',  'Peach___healthy',  'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy',  'Potato___Early_blight',  'Potato___Late_blight',  'Potato___healthy',  'Raspberry___healthy',  'Soybean___healthy',  'Squash___Powdery_mildew',  'Strawberry___Leaf_scorch', 'Strawberry___healthy', 'Tomato___Bacterial_spot',  'Tomato___Early_blight',  'Tomato___Late_blight',  'Tomato___Leaf_Mold',  'Tomato___Septoria_leaf_spot',  'Tomato___Spider_mites Two-spotted_spider_mite',  'Tomato___Target_Spot', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Tomato_mosaic_virus', 'Tomato___healthy']\n",
        "\n",
        "hp[\"num_layers\"] = 6 #reduce num_layers from 12\n",
        "hp[\"hidden_dim\"] = 384 #reduce hidden_dim from 768\n",
        "hp[\"mlp_dim\"] = 1536 #reduce mlp_dim from 3072\n",
        "hp[\"num_heads\"] = 6 #reduce num_heads from 12\n",
        "hp[\"dropout_rate\"] = 0.1\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Paths \"\"\"\n",
        "    dataset_path = \"/content/plantvillage dataset/color\"\n",
        "    model_path = os.path.join(\"/content/files\", \"model.keras\") #fixed path to .keras\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    train_x, valid_x, test_x = load_data(dataset_path)\n",
        "    print(f\"Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "    test_ds = tf_dataset(test_x, batch=hp[\"batch_size\"])\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = ViT(hp) # Use the same model object that was trained.\n",
        "    model.load_weights(model_path)\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "        optimizer=tf.keras.optimizers.Adam(hp[\"lr\"]),\n",
        "        metrics=[\"acc\"]\n",
        "    )\n",
        "\n",
        "    model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "1JNQVJw9VUQp",
        "outputId": "55fd0dcc-1ace-4dd6-d957-8ce480f1f57e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1200 - Valid: 150 - Test: 150\n",
            "input_shape (100, 300)\n",
            "patch_embed (None, 100, 384)\n",
            "pos_embed (100, 384)\n",
            "embed (None, 100, 384)\n",
            "token (None, 1, 384)\n",
            "x (None, 101, 384)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fb3adcdb7aa0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;34m\"\"\" Model \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Use the same model object that was trained.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     model.compile(\n",
            "\u001b[0;32m/content/vit.py\u001b[0m in \u001b[0;36mViT\u001b[0;34m(cf)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;34m\"\"\" Classification Head \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/vit.py\u001b[0m in \u001b[0;36mtransformer_encoder\u001b[0;34m(x, cf)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mskip_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_heads\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hidden_dim\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/random.py\u001b[0m in \u001b[0;36muniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cast_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdraw_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     return tf.random.stateless_uniform(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
          ]
        }
      ]
    }
  ]
}